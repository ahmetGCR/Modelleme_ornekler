{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple ve Multiple Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>V</th>\n",
       "      <th>AP</th>\n",
       "      <th>RH</th>\n",
       "      <th>PE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.96</td>\n",
       "      <td>41.76</td>\n",
       "      <td>1024.07</td>\n",
       "      <td>73.17</td>\n",
       "      <td>463.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.18</td>\n",
       "      <td>62.96</td>\n",
       "      <td>1020.04</td>\n",
       "      <td>59.08</td>\n",
       "      <td>444.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.11</td>\n",
       "      <td>39.40</td>\n",
       "      <td>1012.16</td>\n",
       "      <td>92.14</td>\n",
       "      <td>488.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.86</td>\n",
       "      <td>57.32</td>\n",
       "      <td>1010.24</td>\n",
       "      <td>76.64</td>\n",
       "      <td>446.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.82</td>\n",
       "      <td>37.50</td>\n",
       "      <td>1009.23</td>\n",
       "      <td>96.62</td>\n",
       "      <td>473.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AT      V       AP     RH      PE\n",
       "0  14.96  41.76  1024.07  73.17  463.26\n",
       "1  25.18  62.96  1020.04  59.08  444.37\n",
       "2   5.11  39.40  1012.16  92.14  488.56\n",
       "3  20.86  57.32  1010.24  76.64  446.48\n",
       "4  10.82  37.50  1009.23  96.62  473.90"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# veriyi oku\n",
    "df = pd.read_csv('Power_Plant.csv', delimiter=\",\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# girdileri ve çıktı sutunlarını x ve y değişkenine ata\n",
    "x = df.iloc[:,:-1].values\n",
    "y = df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri setini Eğitim seti ve Test seti olarak ayırma\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Scaling\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "standard_scaler = StandardScaler()\n",
    "x_train_scaled = standard_scaler.fit_transform(x_train)\n",
    "x_test_scaled = standard_scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(x_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(x_test_scaled)\n",
    "\n",
    "y_pred_df = pd.DataFrame(data=y_pred,columns=[\"Tahmini_Sonuc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gerçek_Sonuç</th>\n",
       "      <th>Tahmini_Sonuc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>440.17</td>\n",
       "      <td>438.038829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>450.86</td>\n",
       "      <td>448.223550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>441.76</td>\n",
       "      <td>439.962454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>464.95</td>\n",
       "      <td>464.137305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>467.62</td>\n",
       "      <td>467.208206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889</th>\n",
       "      <td>430.92</td>\n",
       "      <td>437.623002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>466.83</td>\n",
       "      <td>466.445187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1891</th>\n",
       "      <td>446.75</td>\n",
       "      <td>454.009410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>449.99</td>\n",
       "      <td>452.231097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893</th>\n",
       "      <td>440.46</td>\n",
       "      <td>440.081215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1894 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gerçek_Sonuç  Tahmini_Sonuc\n",
       "0           440.17     438.038829\n",
       "1           450.86     448.223550\n",
       "2           441.76     439.962454\n",
       "3           464.95     464.137305\n",
       "4           467.62     467.208206\n",
       "...            ...            ...\n",
       "1889        430.92     437.623002\n",
       "1890        466.83     466.445187\n",
       "1891        446.75     454.009410\n",
       "1892        449.99     452.231097\n",
       "1893        440.46     440.081215\n",
       "\n",
       "[1894 rows x 2 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_df = pd.DataFrame(data=y_test,columns=[\"Gerçek_Sonuç\"])\n",
    "\n",
    "karsılastırma_df = pd.concat([y_test_df,y_pred_df],axis=1)\n",
    "karsılastırma_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9227358762491314"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>V</th>\n",
       "      <th>AP</th>\n",
       "      <th>RH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.45</td>\n",
       "      <td>40.56</td>\n",
       "      <td>1017.84</td>\n",
       "      <td>66.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.70</td>\n",
       "      <td>40.56</td>\n",
       "      <td>1019.04</td>\n",
       "      <td>50.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.88</td>\n",
       "      <td>44.60</td>\n",
       "      <td>1015.52</td>\n",
       "      <td>37.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.64</td>\n",
       "      <td>46.33</td>\n",
       "      <td>1013.33</td>\n",
       "      <td>98.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.01</td>\n",
       "      <td>59.87</td>\n",
       "      <td>1019.00</td>\n",
       "      <td>84.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16.27</td>\n",
       "      <td>58.20</td>\n",
       "      <td>1018.47</td>\n",
       "      <td>80.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.80</td>\n",
       "      <td>41.39</td>\n",
       "      <td>1019.74</td>\n",
       "      <td>74.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.64</td>\n",
       "      <td>39.35</td>\n",
       "      <td>1015.10</td>\n",
       "      <td>91.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11.53</td>\n",
       "      <td>41.14</td>\n",
       "      <td>1025.63</td>\n",
       "      <td>88.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21.83</td>\n",
       "      <td>63.07</td>\n",
       "      <td>1011.57</td>\n",
       "      <td>87.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AT      V       AP     RH\n",
       "0  12.45  40.56  1017.84  66.52\n",
       "1  16.70  40.56  1019.04  50.90\n",
       "2  19.88  44.60  1015.52  37.85\n",
       "3  19.64  46.33  1013.33  98.99\n",
       "4  20.01  59.87  1019.00  84.12\n",
       "5  16.27  58.20  1018.47  80.03\n",
       "6  10.80  41.39  1019.74  74.08\n",
       "7   9.64  39.35  1015.10  91.76\n",
       "8  11.53  41.14  1025.63  88.54\n",
       "9  21.83  63.07  1011.57  87.02"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_dataset_df = pd.read_csv('Power_Plant_Unseen.csv', delimiter=\";\")\n",
    "unseen_dataset_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  12.45,   40.56, 1017.84,   66.52],\n",
       "       [  16.7 ,   40.56, 1019.04,   50.9 ],\n",
       "       [  19.88,   44.6 , 1015.52,   37.85],\n",
       "       [  19.64,   46.33, 1013.33,   98.99],\n",
       "       [  20.01,   59.87, 1019.  ,   84.12],\n",
       "       [  16.27,   58.2 , 1018.47,   80.03],\n",
       "       [  10.8 ,   41.39, 1019.74,   74.08],\n",
       "       [   9.64,   39.35, 1015.1 ,   91.76],\n",
       "       [  11.53,   41.14, 1025.63,   88.54],\n",
       "       [  21.83,   63.07, 1011.57,   87.02],\n",
       "       [   9.51,   40.46, 1018.84,   70.12],\n",
       "       [  28.84,   75.6 , 1018.41,   53.96],\n",
       "       [  25.82,   72.39, 1003.4 ,   86.33],\n",
       "       [  28.47,   69.23, 1013.18,   40.73],\n",
       "       [  19.87,   49.69, 1012.23,   68.57],\n",
       "       [  14.38,   44.84, 1024.59,   81.68],\n",
       "       [  27.37,   65.06, 1013.09,   50.92],\n",
       "       [  28.05,   62.6 , 1017.01,   46.46],\n",
       "       [   8.66,   36.25, 1028.22,   86.96],\n",
       "       [  16.61,   45.87, 1009.34,   97.93],\n",
       "       [  11.28,   42.44, 1014.62,   99.78],\n",
       "       [  21.1 ,   62.66, 1011.19,   83.49],\n",
       "       [  16.47,   44.89, 1010.04,   82.01],\n",
       "       [  30.39,   71.8 , 1010.87,   64.11],\n",
       "       [   8.29,   36.08, 1020.38,   81.53],\n",
       "       [  28.9 ,   68.12, 1011.87,   46.56],\n",
       "       [  18.42,   58.95, 1016.95,   86.77],\n",
       "       [  18.13,   66.86, 1012.9 ,   78.84],\n",
       "       [  26.27,   58.33, 1013.81,   60.43],\n",
       "       [  26.05,   73.88, 1005.67,   82.08],\n",
       "       [  18.2 ,   52.72, 1025.87,   54.26],\n",
       "       [  31.04,   66.54, 1003.83,   53.05],\n",
       "       [  21.67,   62.39, 1007.98,   92.96],\n",
       "       [  24.48,   50.23, 1017.03,   66.89],\n",
       "       [  24.41,   73.67, 1007.39,   86.92],\n",
       "       [  12.77,   36.71, 1013.29,   86.4 ],\n",
       "       [  13.51,   40.89, 1011.03,   84.83],\n",
       "       [  32.13,   74.34, 1003.34,   56.39],\n",
       "       [  19.68,   62.96, 1020.41,   82.26],\n",
       "       [  26.87,   74.99, 1002.48,   71.91],\n",
       "       [  25.63,   56.85, 1012.68,   49.7 ],\n",
       "       [  19.39,   60.1 , 1010.28,   83.31],\n",
       "       [  13.84,   42.18, 1015.74,   79.76],\n",
       "       [  24.6 ,   57.32, 1012.48,   45.14],\n",
       "       [  34.14,   74.34, 1000.19,   43.56],\n",
       "       [  29.61,   67.07, 1005.91,   39.28],\n",
       "       [  31.94,   74.99, 1002.05,   34.12],\n",
       "       [  26.98,   43.77, 1010.95,   40.8 ],\n",
       "       [  15.92,   37.64, 1014.93,   83.73],\n",
       "       [  14.49,   41.92, 1030.3 ,   56.62],\n",
       "       [  26.71,   76.86, 1002.86,   74.5 ],\n",
       "       [  26.73,   49.02, 1007.75,   67.73],\n",
       "       [  28.53,   49.3 , 1003.83,   59.69],\n",
       "       [  26.85,   75.6 , 1017.43,   74.55],\n",
       "       [  10.25,   37.14, 1013.14,   70.73],\n",
       "       [  10.88,   44.63, 1020.52,   86.81],\n",
       "       [  26.75,   64.79, 1017.79,   54.31],\n",
       "       [  13.45,   43.14, 1015.5 ,   74.33],\n",
       "       [  23.96,   65.34, 1015.52,   56.82],\n",
       "       [  14.32,   45.08, 1023.24,   84.53],\n",
       "       [  13.16,   40.71, 1021.99,   77.91],\n",
       "       [  23.4 ,   65.06, 1014.32,   67.38],\n",
       "       [  26.5 ,   66.75, 1018.48,   61.62],\n",
       "       [   7.39,   39.85, 1011.63,   83.61],\n",
       "       [  25.97,   70.32, 1007.48,   57.01],\n",
       "       [  25.99,   74.67, 1016.59,   83.39],\n",
       "       [  25.87,   44.57, 1007.43,   55.92],\n",
       "       [  28.66,   77.95, 1009.56,   69.07],\n",
       "       [   7.84,   41.39, 1018.21,   91.92],\n",
       "       [  31.91,   69.89, 1014.59,   54.51],\n",
       "       [  31.94,   69.98, 1013.32,   56.17],\n",
       "       [  30.03,   70.02, 1010.07,   64.2 ],\n",
       "       [  22.43,   63.94, 1012.76,   93.24],\n",
       "       [  22.86,   58.96, 1014.03,   54.96],\n",
       "       [  14.05,   40.35, 1011.52,   66.21],\n",
       "       [  12.04,   41.58, 1018.02,   88.91],\n",
       "       [  19.31,   44.71, 1016.13,   30.59],\n",
       "       [  16.76,   43.77, 1012.25,   77.95],\n",
       "       [  31.5 ,   70.32, 1011.44,   64.09],\n",
       "       [  14.43,   35.85, 1021.99,   78.25],\n",
       "       [   9.39,   41.79, 1021.6 ,   50.09],\n",
       "       [  25.15,   62.91, 1012.23,   48.22],\n",
       "       [   9.66,   41.82, 1033.19,   73.19],\n",
       "       [  18.31,   42.23, 1012.88,   79.32],\n",
       "       [  28.21,   70.02, 1010.58,   51.34],\n",
       "       [  17.48,   58.95, 1016.49,   90.35],\n",
       "       [  19.92,   38.52, 1018.15,   60.68],\n",
       "       [  23.1 ,   70.79, 1006.53,   90.81],\n",
       "       [  22.61,   54.42, 1014.74,   75.87],\n",
       "       [  25.6 ,   63.76, 1010.18,   67.43],\n",
       "       [  25.84,   67.83, 1009.26,   59.55],\n",
       "       [  22.99,   60.95, 1015.14,   69.86],\n",
       "       [  22.61,   45.38, 1013.92,   62.91],\n",
       "       [  17.54,   44.58, 1016.56,   79.  ],\n",
       "       [  26.18,   52.36, 1013.46,   56.65],\n",
       "       [  20.97,   47.43, 1007.64,   71.18],\n",
       "       [  14.1 ,   41.16, 1021.26,   73.87],\n",
       "       [  17.83,   66.86, 1011.65,   77.31],\n",
       "       [   8.46,   40.8 , 1023.57,   81.27],\n",
       "       [  30.92,   78.05, 1011.  ,   59.62]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unseen_dataset\n",
    "unseen_dataset = unseen_dataset_df.iloc[:, :].values\n",
    "unseen_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  12.45,   40.56, 1017.84,   66.52],\n",
       "       [  16.7 ,   40.56, 1019.04,   50.9 ],\n",
       "       [  19.88,   44.6 , 1015.52,   37.85],\n",
       "       [  19.64,   46.33, 1013.33,   98.99],\n",
       "       [  20.01,   59.87, 1019.  ,   84.12],\n",
       "       [  16.27,   58.2 , 1018.47,   80.03],\n",
       "       [  10.8 ,   41.39, 1019.74,   74.08],\n",
       "       [   9.64,   39.35, 1015.1 ,   91.76],\n",
       "       [  11.53,   41.14, 1025.63,   88.54],\n",
       "       [  21.83,   63.07, 1011.57,   87.02],\n",
       "       [   9.51,   40.46, 1018.84,   70.12],\n",
       "       [  28.84,   75.6 , 1018.41,   53.96],\n",
       "       [  25.82,   72.39, 1003.4 ,   86.33],\n",
       "       [  28.47,   69.23, 1013.18,   40.73],\n",
       "       [  19.87,   49.69, 1012.23,   68.57],\n",
       "       [  14.38,   44.84, 1024.59,   81.68],\n",
       "       [  27.37,   65.06, 1013.09,   50.92],\n",
       "       [  28.05,   62.6 , 1017.01,   46.46],\n",
       "       [   8.66,   36.25, 1028.22,   86.96],\n",
       "       [  16.61,   45.87, 1009.34,   97.93],\n",
       "       [  11.28,   42.44, 1014.62,   99.78],\n",
       "       [  21.1 ,   62.66, 1011.19,   83.49],\n",
       "       [  16.47,   44.89, 1010.04,   82.01],\n",
       "       [  30.39,   71.8 , 1010.87,   64.11],\n",
       "       [   8.29,   36.08, 1020.38,   81.53],\n",
       "       [  28.9 ,   68.12, 1011.87,   46.56],\n",
       "       [  18.42,   58.95, 1016.95,   86.77],\n",
       "       [  18.13,   66.86, 1012.9 ,   78.84],\n",
       "       [  26.27,   58.33, 1013.81,   60.43],\n",
       "       [  26.05,   73.88, 1005.67,   82.08],\n",
       "       [  18.2 ,   52.72, 1025.87,   54.26],\n",
       "       [  31.04,   66.54, 1003.83,   53.05],\n",
       "       [  21.67,   62.39, 1007.98,   92.96],\n",
       "       [  24.48,   50.23, 1017.03,   66.89],\n",
       "       [  24.41,   73.67, 1007.39,   86.92],\n",
       "       [  12.77,   36.71, 1013.29,   86.4 ],\n",
       "       [  13.51,   40.89, 1011.03,   84.83],\n",
       "       [  32.13,   74.34, 1003.34,   56.39],\n",
       "       [  19.68,   62.96, 1020.41,   82.26],\n",
       "       [  26.87,   74.99, 1002.48,   71.91],\n",
       "       [  25.63,   56.85, 1012.68,   49.7 ],\n",
       "       [  19.39,   60.1 , 1010.28,   83.31],\n",
       "       [  13.84,   42.18, 1015.74,   79.76],\n",
       "       [  24.6 ,   57.32, 1012.48,   45.14],\n",
       "       [  34.14,   74.34, 1000.19,   43.56],\n",
       "       [  29.61,   67.07, 1005.91,   39.28],\n",
       "       [  31.94,   74.99, 1002.05,   34.12],\n",
       "       [  26.98,   43.77, 1010.95,   40.8 ],\n",
       "       [  15.92,   37.64, 1014.93,   83.73],\n",
       "       [  14.49,   41.92, 1030.3 ,   56.62],\n",
       "       [  26.71,   76.86, 1002.86,   74.5 ],\n",
       "       [  26.73,   49.02, 1007.75,   67.73],\n",
       "       [  28.53,   49.3 , 1003.83,   59.69],\n",
       "       [  26.85,   75.6 , 1017.43,   74.55],\n",
       "       [  10.25,   37.14, 1013.14,   70.73],\n",
       "       [  10.88,   44.63, 1020.52,   86.81],\n",
       "       [  26.75,   64.79, 1017.79,   54.31],\n",
       "       [  13.45,   43.14, 1015.5 ,   74.33],\n",
       "       [  23.96,   65.34, 1015.52,   56.82],\n",
       "       [  14.32,   45.08, 1023.24,   84.53],\n",
       "       [  13.16,   40.71, 1021.99,   77.91],\n",
       "       [  23.4 ,   65.06, 1014.32,   67.38],\n",
       "       [  26.5 ,   66.75, 1018.48,   61.62],\n",
       "       [   7.39,   39.85, 1011.63,   83.61],\n",
       "       [  25.97,   70.32, 1007.48,   57.01],\n",
       "       [  25.99,   74.67, 1016.59,   83.39],\n",
       "       [  25.87,   44.57, 1007.43,   55.92],\n",
       "       [  28.66,   77.95, 1009.56,   69.07],\n",
       "       [   7.84,   41.39, 1018.21,   91.92],\n",
       "       [  31.91,   69.89, 1014.59,   54.51],\n",
       "       [  31.94,   69.98, 1013.32,   56.17],\n",
       "       [  30.03,   70.02, 1010.07,   64.2 ],\n",
       "       [  22.43,   63.94, 1012.76,   93.24],\n",
       "       [  22.86,   58.96, 1014.03,   54.96],\n",
       "       [  14.05,   40.35, 1011.52,   66.21],\n",
       "       [  12.04,   41.58, 1018.02,   88.91],\n",
       "       [  19.31,   44.71, 1016.13,   30.59],\n",
       "       [  16.76,   43.77, 1012.25,   77.95],\n",
       "       [  31.5 ,   70.32, 1011.44,   64.09],\n",
       "       [  14.43,   35.85, 1021.99,   78.25],\n",
       "       [   9.39,   41.79, 1021.6 ,   50.09],\n",
       "       [  25.15,   62.91, 1012.23,   48.22],\n",
       "       [   9.66,   41.82, 1033.19,   73.19],\n",
       "       [  18.31,   42.23, 1012.88,   79.32],\n",
       "       [  28.21,   70.02, 1010.58,   51.34],\n",
       "       [  17.48,   58.95, 1016.49,   90.35],\n",
       "       [  19.92,   38.52, 1018.15,   60.68],\n",
       "       [  23.1 ,   70.79, 1006.53,   90.81],\n",
       "       [  22.61,   54.42, 1014.74,   75.87],\n",
       "       [  25.6 ,   63.76, 1010.18,   67.43],\n",
       "       [  25.84,   67.83, 1009.26,   59.55],\n",
       "       [  22.99,   60.95, 1015.14,   69.86],\n",
       "       [  22.61,   45.38, 1013.92,   62.91],\n",
       "       [  17.54,   44.58, 1016.56,   79.  ],\n",
       "       [  26.18,   52.36, 1013.46,   56.65],\n",
       "       [  20.97,   47.43, 1007.64,   71.18],\n",
       "       [  14.1 ,   41.16, 1021.26,   73.87],\n",
       "       [  17.83,   66.86, 1011.65,   77.31],\n",
       "       [   8.46,   40.8 , 1023.57,   81.27],\n",
       "       [  30.92,   78.05, 1011.  ,   59.62]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard Scaling\n",
    "unseen_dataset_scaled = standard_scaler.transform(unseen_dataset)\n",
    "unseen_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([473.27653664, 467.42705403, 462.05153816, 452.15393346,\n",
       "       450.95051848, 459.39290014, 475.25184993, 474.91521208,\n",
       "       471.88752588, 445.67350725, 478.61473432, 434.52821851,\n",
       "       435.1778034 , 438.58377566, 455.73123407, 466.39934483,\n",
       "       440.10736408, 440.29031306, 479.14655636, 458.20788134,\n",
       "       469.61212689, 447.76412051, 461.31974574, 430.268134  ,\n",
       "       480.32699342, 436.97689207, 453.77455479, 453.51525088,\n",
       "       442.39347123, 435.18830668, 461.4441645 , 431.58042869,\n",
       "       444.98218769, 447.0121156 , 437.81628668, 470.08217907,\n",
       "       467.74395296, 427.00810701, 451.25852629, 434.74457481,\n",
       "       445.67173145, 451.73693719, 467.88063183, 448.32614508,\n",
       "       424.89549633, 436.63178724, 430.73685357, 447.41171227,\n",
       "       464.13894906, 471.2423451 , 434.22629215, 442.14485007,\n",
       "       439.56641149, 435.10671666, 477.49280141, 472.32642688,\n",
       "       441.13635689, 469.28683834, 446.00371616, 465.92279182,\n",
       "       470.24748184, 445.41097088, 440.03465702, 480.3659844 ,\n",
       "       440.3286622 , 435.56098397, 446.78340077, 431.37209614,\n",
       "       478.16473805, 429.46913091, 429.04560988, 431.34089727,\n",
       "       443.34776994, 449.9042797 , 469.82427572, 470.25836289,\n",
       "       464.36079244, 461.79371311, 428.45236783, 468.82092317,\n",
       "       481.92503843, 445.40366533, 478.35739669, 458.89899466,\n",
       "       437.05141014, 455.03657992, 459.89319757, 440.41927374,\n",
       "       448.15192709, 441.09767822, 440.87248839, 446.84559778,\n",
       "       452.32357889, 460.14257251, 444.5697552 , 453.38895001,\n",
       "       468.88218674, 454.28214715, 479.10644799, 428.46971354])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_unseen = regressor.predict(unseen_dataset_scaled)\n",
    "y_pred_unseen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tahmini_Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>473.276537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>467.427054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>462.051538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>452.153933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>450.950518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>459.392900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>475.251850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>474.915212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>471.887526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>445.673507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tahmini_Output\n",
       "0      473.276537\n",
       "1      467.427054\n",
       "2      462.051538\n",
       "3      452.153933\n",
       "4      450.950518\n",
       "5      459.392900\n",
       "6      475.251850\n",
       "7      474.915212\n",
       "8      471.887526\n",
       "9      445.673507"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_unseen_df = pd.DataFrame(y_pred_unseen, columns=[\"Tahmini_Output\"])\n",
    "y_pred_unseen_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>V</th>\n",
       "      <th>AP</th>\n",
       "      <th>RH</th>\n",
       "      <th>Tahmini_Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.45</td>\n",
       "      <td>40.56</td>\n",
       "      <td>1017.84</td>\n",
       "      <td>66.52</td>\n",
       "      <td>473.276537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.70</td>\n",
       "      <td>40.56</td>\n",
       "      <td>1019.04</td>\n",
       "      <td>50.90</td>\n",
       "      <td>467.427054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.88</td>\n",
       "      <td>44.60</td>\n",
       "      <td>1015.52</td>\n",
       "      <td>37.85</td>\n",
       "      <td>462.051538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.64</td>\n",
       "      <td>46.33</td>\n",
       "      <td>1013.33</td>\n",
       "      <td>98.99</td>\n",
       "      <td>452.153933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.01</td>\n",
       "      <td>59.87</td>\n",
       "      <td>1019.00</td>\n",
       "      <td>84.12</td>\n",
       "      <td>450.950518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>20.97</td>\n",
       "      <td>47.43</td>\n",
       "      <td>1007.64</td>\n",
       "      <td>71.18</td>\n",
       "      <td>453.388950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>14.10</td>\n",
       "      <td>41.16</td>\n",
       "      <td>1021.26</td>\n",
       "      <td>73.87</td>\n",
       "      <td>468.882187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>17.83</td>\n",
       "      <td>66.86</td>\n",
       "      <td>1011.65</td>\n",
       "      <td>77.31</td>\n",
       "      <td>454.282147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>8.46</td>\n",
       "      <td>40.80</td>\n",
       "      <td>1023.57</td>\n",
       "      <td>81.27</td>\n",
       "      <td>479.106448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>30.92</td>\n",
       "      <td>78.05</td>\n",
       "      <td>1011.00</td>\n",
       "      <td>59.62</td>\n",
       "      <td>428.469714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AT      V       AP     RH  Tahmini_Output\n",
       "0   12.45  40.56  1017.84  66.52      473.276537\n",
       "1   16.70  40.56  1019.04  50.90      467.427054\n",
       "2   19.88  44.60  1015.52  37.85      462.051538\n",
       "3   19.64  46.33  1013.33  98.99      452.153933\n",
       "4   20.01  59.87  1019.00  84.12      450.950518\n",
       "..    ...    ...      ...    ...             ...\n",
       "95  20.97  47.43  1007.64  71.18      453.388950\n",
       "96  14.10  41.16  1021.26  73.87      468.882187\n",
       "97  17.83  66.86  1011.65  77.31      454.282147\n",
       "98   8.46  40.80  1023.57  81.27      479.106448\n",
       "99  30.92  78.05  1011.00  59.62      428.469714\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df = unseen_dataset_df.merge(y_pred_unseen_df, how=\"left\", left_index=True, right_index=True)\n",
    "all_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
